{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = cv2.imread(\"images/1.jpg\")\n",
    "img2 = cv2.imread(\"images/2.jpg\")\n",
    "\n",
    "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imwrite(\"test1.jpg\", img1_gray)\n",
    "cv2.imwrite(\"test2.jpg\", img2_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_feature:愈抓出的特徵點\n",
    "orb = cv2.ORB_create(nfeatures=2000)\n",
    "\n",
    "# Find the key points and descriptors with ORB\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(img2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"points_img1.jpg\", cv2.drawKeypoints(img1, keypoints1, None, (0, 255, 255)))\n",
    "cv2.imwrite(\"points_img2.jpg\", cv2.drawKeypoints(img2, keypoints2, None, (0, 255, 255)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BFMatcher object.\n",
    "# It will find all of the matching keypoints on two images\n",
    "bf = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "# Find matching points\n",
    "matches = bf.knnMatch(descriptors1, descriptors2,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(img1, keypoints1, img2, keypoints2, matches):\n",
    "    r, c = img1.shape[:2]\n",
    "    r1, c1 = img2.shape[:2]\n",
    "\n",
    "    # Create a blank image with the size of the first image + second image\n",
    "    output_img = np.zeros((max([r, r1]), c+c1, 3), dtype='uint8')\n",
    "    output_img[:r, :c, :] = np.dstack([img1, img1, img1])\n",
    "    output_img[:r1, c:c+c1, :] = np.dstack([img2, img2, img2])\n",
    "    \n",
    "    # Go over all of the matching points and extract them\n",
    "    for match in matches:\n",
    "        img1_idx = match.queryIdx\n",
    "        img2_idx = match.trainIdx\n",
    "        (x1, y1) = keypoints1[img1_idx].pt\n",
    "        (x2, y2) = keypoints2[img2_idx].pt\n",
    "        # Draw circles on the keypoints\n",
    "        cv2.circle(output_img, (int(x1),int(y1)), 4, (0, 255, 255), 1)\n",
    "        cv2.circle(output_img, (int(x2)+c,int(y2)), 4, (0, 255, 255), 1)\n",
    "\n",
    "        # Connect the same keypoints\n",
    "        cv2.line(output_img, (int(x1),int(y1)), (int(x2)+c,int(y2)), (0, 255, 255), 1)\n",
    "\n",
    "    return output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches = []\n",
    "for m, n in matches:\n",
    "    all_matches.append(m)\n",
    "img3 = draw_matches(img1_gray, keypoints1, img2_gray, keypoints2, all_matches[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./test3.jpg', img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best matches\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.6 * n.distance:\n",
    "        good.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite( \"./test4.jpg\",cv2.drawKeypoints(img1, [keypoints1[m.queryIdx] for m in good], None, (0, 255, 255)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./test5.jpg',cv2.drawKeypoints(img2, [keypoints2[m.trainIdx] for m in good], None, (255, 0, 255)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpImages(img1, img2, H):\n",
    "    rows1, cols1 = img1.shape[:2]\n",
    "    rows2, cols2 = img2.shape[:2]\n",
    "    print(rows1, cols1, rows2, cols2)\n",
    "    list_of_points_1 = np.float32([[0,0], [0, rows1],[cols1, rows1], [cols1, 0]]).reshape(-1, 1, 2)\n",
    "    temp_points = np.float32([[0,0], [0,rows2], [cols2,rows2], [cols2,0]]).reshape(-1,1,2)\n",
    "    print(list_of_points_1)\n",
    "    print(temp_points)\n",
    "    # When we have established a homography we need to warp perspective\n",
    "    # Change field of view\n",
    "    #把圖片一的四個角以Ｈ做基礎來形變\n",
    "    list_of_points_2 = cv2.perspectiveTransform(temp_points, H)\n",
    "    print(list_of_points_2)\n",
    "    \n",
    "    list_of_points = np.concatenate((list_of_points_1,list_of_points_2), axis=0)\n",
    "\n",
    "    #計算圖片邊界\n",
    "    [x_min, y_min] = np.int32(list_of_points.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max] = np.int32(list_of_points.max(axis=0).ravel() + 0.5)\n",
    "    \n",
    "    print(x_min ,y_min,  x_max,y_max )\n",
    "    translation_dist = [-x_min,-y_min]\n",
    "\n",
    "    #計算再來圖片1要移到哪裡，H_translation代表再來圖片的座標系\n",
    "    H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
    "    #將圖片一位移後貼上\n",
    "    print(H_translation.dot(H))\n",
    "    output_img = cv2.warpPerspective(img2, H_translation.dot(H), (x_max-x_min, y_max-y_min))\n",
    "    cv2.imwrite(\"./aaa.jpg\",output_img)\n",
    "    #把圖片二裁切後貼上\n",
    "    output_img[translation_dist[1]:rows1+translation_dist[1], translation_dist[0]:cols1+translation_dist[0]] = img1\n",
    "\n",
    "    return output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 405 250 408\n",
      "[[[  0.   0.]]\n",
      "\n",
      " [[  0. 249.]]\n",
      "\n",
      " [[405. 249.]]\n",
      "\n",
      " [[405.   0.]]]\n",
      "[[[  0.   0.]]\n",
      "\n",
      " [[  0. 250.]]\n",
      "\n",
      " [[408. 250.]]\n",
      "\n",
      " [[408.   0.]]]\n",
      "[[[-297.6418       -0.7855145 ]]\n",
      "\n",
      " [[-298.31973     252.05121   ]]\n",
      "\n",
      " [[ 112.56327     248.51718   ]]\n",
      "\n",
      " [[ 112.867966     -0.98228323]]]\n",
      "-298 -1 405 252\n",
      "[[ 1.01960852e+00 -2.71047967e-03  3.58175316e-01]\n",
      " [-4.81696088e-04  1.01043754e+00  2.14485550e-01]\n",
      " [ 3.27527812e-05 -3.59363681e-06  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Set minimum match condition\n",
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "if len(good) > MIN_MATCH_COUNT:\n",
    "    # Convert keypoints to an argument for findHomography\n",
    "    src_pts = np.float32([ keypoints1[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ keypoints2[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "    # Establish a homography\n",
    "    M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "    result = warpImages(img2, img1, M)\n",
    "    cv2.imwrite(\"./test6.jpg\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00984819e+00, -1.63957590e-03, -2.97641825e+02],\n",
       "       [-5.14448870e-04,  1.01044113e+00, -7.85514450e-01],\n",
       "       [ 3.27527812e-05, -3.59363681e-06,  1.00000000e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
